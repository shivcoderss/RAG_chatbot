{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9525294c",
   "metadata": {},
   "source": [
    "# RAG Q&A Chatbot for Loan Approval Dataset (Colab Version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ba11b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas faiss-cpu sentence-transformers transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcaff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "from transformers import pipeline, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79998bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload(),
    "\n",
    "df = pd.read_csv(\"Training Dataset.csv\")\n",
    "df.fillna(\"N/A\", inplace=True)\n",
    "df_clean = df.replace(\"N/A\", \"\")\n",
    "docs = [\" | \".join(f\"{col}: {row[col]}\" for col in df_clean.columns if str(row[col]).strip()) for _, row in df_clean.iterrows()]\n",
    "print(f\"Loaded {len(docs)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9400514",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = embed_model.encode(docs, show_progress_bar=True)\n",
    "\n",
    "index = faiss.IndexFlatL2(doc_embeddings.shape[1])\n",
    "index.add(np.array(doc_embeddings))\n",
    "print(\"FAISS index created and populated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d69aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query, k=2):\n",
    "    query_emb = embed_model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_emb), k)\n",
    "    return [docs[i] for i in indices[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3147616",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"google/flan-t5-small\"\n",
    "qa_pipeline = pipeline(\"text2text-generation\", model=model_id, tokenizer=model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fed21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncate_context(context, query, max_tokens=512):\n",
    "    prompt_template = \"Context: {}\\n\\nQuestion: {}\\nAnswer:\"\n",
    "    context_parts = context.split('\\n')\n",
    "    while True:\n",
    "        prompt = prompt_template.format(\"\\n\".join(context_parts), query)\n",
    "        tokenized = tokenizer(prompt, return_tensors=\"pt\")\n",
    "        if tokenized.input_ids.shape[1] <= max_tokens:\n",
    "            return \"\\n\".join(context_parts)\n",
    "        context_parts = context_parts[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5708241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(query, context):\n",
    "    context = truncate_context(context, query)\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    result = qa_pipeline(prompt, max_new_tokens=100, do_sample=False)\n",
    "    return result[0]['generated_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ee3b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chatbot(query):\n",
    "    retrieved_docs = retrieve(query)\n",
    "    context = \"\\n\".join(retrieved_docs)\n",
    "    return generate_answer(query, context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90a5177",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What factors increase the chances of loan approval?\"\n",
    "response = rag_chatbot(query)\n",
    "print(\"\\nQuestion:\", query)\n",
    "print(\"\\nAnswer:\", response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
